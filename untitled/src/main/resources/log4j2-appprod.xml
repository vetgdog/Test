<?xml version="1.0" encoding="UTF-8" ?>
<!-- 本项目全部使用log4j2性能上有很大提升 -->

<!--monitorInterval="60" 自动检测配置文件更改时间 单位为秒 最小值为5 -->
<!--Configuration后面的status，这个用于设置log4j2自身内部的信息输出，可以不设置，当设置成trace时，你会看到log4j2内部各种详细输出。 -->
<configuration monitorInterval="20" status="OFF">
    <!--日志变量  -->
    <properties>
        <!-- 日志主目录 ，需要保存到文件时请自己配置-->
        <property name="LOG_HOME">./zzlogs/cms</property>
        <!-- 日志备份目录 -->
        <property name="BACKUP_HOME">./zzlogs/cms/backup</property>
        <!-- 日志输出级别 -->
        <property name="OUTPUT_LOG_LEVEL">info</property>
        <!-- 日志输出格式 -->
        <property name="LOG_PATTERN">
            <!-- 输出格式%d{HH:mm:ss}时间24小时制  -->
            <!-- %-5p日志级别 5位左对齐 [%t]线程名 [%c]类名 -->
            <!--%l：输出日志事件的发生位置，相当于%c.%M(%F:%L)的组合，包括类全名、方法、文件名以及在代码中的行数。例如：test.TestLog4j.main(TestLog4j.java:10)。  -->
            <!-- 另一种输出风格<PatternLayout pattern="级别%-5p [%d{YYYY-MM-dd HH:mm:ss}] [%t] 位置[%l] - 信息:%msg%n" /> -->
            <!-- [%-5p][%d{yy-MM-dd HH:mm:ss}][%t]==>%m==>%c==>%L%n -->
            [%-5p] [%d{YYYY-MM-dd HH:mm:ss}] [cms] [%t] ==> %msg%n
        </property>
        <property name="LOG_PATTERN_EX">
            <!-- 下面注释中 %traceid 为SkyWalking 中的traceid -->
            [%-5p] [%d{YYYY-MM-dd HH:mm:ss}] [cms] T:[%X{traceId}] S:[%X{sessionId}] U:[%X{userId}] [%t] ==> [%traceId] %msg%n
        </property>
        <!-- 日志保留天数 -->
        <property name="EVERY_FILE_COUNT">31</property>
        <!-- 日志切割的最小单位 -->
        <property name="EVERY_FILE_SIZE">20M</property>
    </properties>

    <appenders>
        <!--Kafka输出  -->
             <!--   <Kafka name="kafka_log" topic="zz-log-topic" syncSend="false" ignoreExceptions="false">
                    <PatternLayout pattern="${LOG_PATTERN_EX}"/>
                    <Property name="bootstrap.servers">@log.kafka.bootstrap.servers@</Property>
                    <Property name="max.block.ms">10000</Property>
                </Kafka>-->
        <!--控制台输出  -->
        <console name="console" target="SYSTEM_OUT">
            <PatternLayout pattern="${LOG_PATTERN}"/>
        </console>
        <!--每次大小超过size，则这size大小的日志会自动进行压缩，作为存档 -->
<!--        <rollingFile name="file_log" fileName="${LOG_HOME}/cms.log"-->
<!--                     filePattern="${LOG_HOME}/cms-%d{yyyy-MM-dd}-%i.log.gz">-->
<!--            <PatternLayout charset="UTF-8" pattern="${LOG_PATTERN_EX}"/>-->
<!--            &lt;!&ndash; 日志切割的最小单位 &ndash;&gt;-->
<!--            <SizeBasedTriggeringPolicy size="${EVERY_FILE_SIZE}"/>-->
<!--            &lt;!&ndash; 默认的日志文件数量 &ndash;&gt;-->
<!--            <DefaultRolloverStrategy max="${EVERY_FILE_COUNT}"/>-->
<!--        </rollingFile>-->
        <rollingFile name="LOG_HOME" filename="${LOG_HOME}/error.log"
                     filePattern="${LOG_HOME}/cms-%d{yyyy-MM-dd}-%i.log.gz" append="true">
            <ThresholdFilter level="error" onMatch="ACCEPT" onMismatch="DENY"/>
            <PatternLayout charset="UTF-8" pattern="${LOG_PATTERN_EX}"/>
            <SizeBasedTriggeringPolicy size="${EVERY_FILE_SIZE}"/>
            <DefaultRolloverStrategy max="${EVERY_FILE_COUNT}"/>
        </rollingFile>
    </appenders>

    <!-- 然后定义logger，只有定义了logger并引入的appender，appender才会生效 -->
    <!-- 这里我们把输出到控制台appender的日志级别设置为DEBUG，便于调试。但是输出文件我们缺省为INFO，两者均可随时修改。-->
    <Loggers>
        <Root level="${OUTPUT_LOG_LEVEL}">
            <AppenderRef ref="console"/>
        </Root>
        <Logger name="springfox.documentation" additivity="false" level="error">
            <AppenderRef ref="console"/>
        </Logger>
        <!-- AsyncLogger 是基于Disruptor的全量异步队列，性能极高，队列默认大小4096。-->
        <!-- 队列默认值可通过JVM参数设置，参考博客：https://www.jianshu.com/p/82469047acbf -->
        <AsyncLogger name="com.metaxsire" additivity="false" level="info">
            <AppenderRef ref="console"/>
            <!--            <AppenderRef ref="kafka_log"/>-->
            <AppenderRef ref="file_log"/>
        </AsyncLogger>
        <!-- 这里将dao的日志级别设置为DEBUG，是为了SQL语句的输出 -->
        <AsyncLogger name="com.metaxsire.cmsservice.dao" additivity="false" level="debug">
            <AppenderRef ref="console"/>
            <!--                        <AppenderRef ref="kafka_log"/>-->
            <AppenderRef ref="file_log"/>
        </AsyncLogger>
        <!--        错误日志输出-->
        <AsyncLogger name="com.metaxsire" level="error" additivity="false" includeLocation="true">
            <AppenderRef ref="LOG_HOME"/>
            <AppenderRef ref="console"/>
        </AsyncLogger>
    </Loggers>
</configuration>